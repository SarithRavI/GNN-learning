{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6f20494-0b9d-4515-ba42-0456bd47d9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import spektral \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1fd9ff1-38ff-484e-9ef8-78e2964aafb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you encounter InternalError: Blas xGEMM launch failed  error \n",
    "# I did encounter !! :((\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce96b0e6-f3e3-48b1-adf4-99624508fa93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\anaconda3\\envs\\tensorflow_learning\\lib\\site-packages\\scipy\\sparse\\_index.py:125: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "cora= spektral.datasets.citation.Citation('cora',random_split=True,dtype= np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9126daef-a4ed-4b94-b586-0e7db9c9909f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\anaconda3\\envs\\tensorflow_learning\\lib\\site-packages\\scipy\\sparse\\_index.py:125: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_arrayXarray(i, j, x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "spektral.data.graph.Graph"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora_g =  cora.read()[0]\n",
    "type(cora_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7857923-6272-4411-849f-b7c4035a0fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `x`: np.array, the node features (shape `(n_nodes, n_node_features)`);\n",
    "# `a`: np.array or scipy.sparse matrix, the adjacency matrix (shape `(n_nodes, n_nodes)`);\n",
    "# `e`: np.array, the edge features (shape `(n_nodes, n_nodes, n_edge_features)` or `(n_edges, n_edge_features)`);\n",
    "# `y`: np.array, the node or graph labels (shape `(n_nodes, n_labels)` or `(n_labels, )`);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1894728-9c9d-4a55-9147-c67263e52829",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj= cora_g.a # note that this is a numpy sparse matrix \n",
    "features= cora_g.x\n",
    "labels=cora_g.y\n",
    "train_mask=cora.mask_tr\n",
    "val_mask=cora.mask_va\n",
    "test_mask= cora.mask_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb930bb7-4496-4e30-bb8c-0131d84952db",
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = adj.todense()+np.eye(adj.shape[0])\n",
    "adj = adj.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1df86914-f5c8-4ff6-b81a-094d950acf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of adj:  float32  type of features:  float32\n"
     ]
    }
   ],
   "source": [
    "print('type of adj: ',adj.dtype,' type of features: ', features.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "382efe99-b5d6-43c0-9aff-a4ae7f7a30c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 140\n",
      "validation size: 210\n",
      "test size: 2358\n",
      "number of node features: 1433\n"
     ]
    }
   ],
   "source": [
    "print(f\"train size: {np.sum(train_mask)}\")\n",
    "print(f\"validation size: {np.sum(val_mask)}\")\n",
    "print(f\"test size: {np.sum(test_mask)}\")\n",
    "print(f\"number of node features: {cora.n_node_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d01b6f92-ea4e-4920-9301-e0c4c36379a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_softmax_cross_entropy(logits,labels,mask): #loss\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=labels)\n",
    "    mask = tf.cast(mask , dtype = tf.float32)\n",
    "    mask /= tf.reduce_mean(mask)\n",
    "    loss *= mask\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "def masked_accuracy(logits,labels, mask):\n",
    "    correct_prediction = tf.equal(tf.argmax(logits,1), tf.argmax(labels,1))\n",
    "    accuracy_all = tf.cast(correct_prediction,tf.float32)\n",
    "    mask = tf.cast(mask,tf.float32)\n",
    "    mask /= tf.reduce_mean(mask)\n",
    "    accuracy_all *= mask\n",
    "    return tf.reduce_mean(accuracy_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5847a9a3-703a-430f-acf1-599fd6dcbf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining GCN layer without normalization \n",
    "def gcn_layer(fts, adj, transform, activation):  \n",
    "    seq_fts = transform(fts)\n",
    "    ret_fts = tf.matmul(adj,seq_fts)\n",
    "    return activation(ret_fts) \n",
    "\n",
    "# creating custom layer \n",
    "# class GNNlayer(tf.keras.Model):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "271b01ea-dff8-4247-b41f-f52f20d4bcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm,trange\n",
    "from time import sleep \n",
    "def train_cora(fts,adj,gnn_lyr,units, epochs ,lr ):\n",
    "    \n",
    "    best_accuracy=0.0\n",
    "    \n",
    "    layer1 = tf.keras.layers.Dense(units) # transform function for first GNN layer\n",
    "    layer2 = tf.keras.layers.Dense(7) # transform function for second GNN layer \n",
    "    \n",
    "    def cora_gnn(fts,adj):   # entire GNN architecutre\n",
    "        hidden = gnn_lyr(fts,adj,layer1,tf.nn.relu) # first layer of the GNN architecture \n",
    "        logits = gnn_lyr(hidden,adj,layer2, tf.identity) \n",
    "        return logits \n",
    "    #custom training loop\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "    \n",
    "    \n",
    "    def getMetrics(predicts):\n",
    "        \n",
    "        nonlocal best_accuracy\n",
    "        val_accuracy = masked_accuracy(predicts, labels, val_mask)\n",
    "        test_accuracy = masked_accuracy(predicts, labels, test_mask)\n",
    "        \n",
    "        if val_accuracy>best_accuracy:\n",
    "            best_accuracy=val_accuracy\n",
    "            tqdm.write(\"\\rEpoch {}/{} | Training loss {:.4f} |  Val accuracy {:.4f} | Test accuracy {:.4f}\".\n",
    "                  format(epoch,epochs,loss.numpy(),val_accuracy.numpy(),test_accuracy.numpy()),\n",
    "                 end=\"\\n\" if epoch<epochs+1 else \"\" )\n",
    "            \n",
    "    for epoch in trange(1,epochs+1):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = cora_gnn(fts,adj)  #calculated logits \n",
    "            loss = masked_softmax_cross_entropy(logits, labels, train_mask)\n",
    "            \n",
    "        variables = tape.watched_variables()\n",
    "        if epoch==1 :\n",
    "            print(len(variables))\n",
    "        gradients = tape.gradient(loss, variables)\n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "        \n",
    "        # I'm gonna calculate predicts again \n",
    "        predicts= cora_gnn(fts,adj)\n",
    "        sleep(0.001)\n",
    "        getMetrics(predicts)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e90981e4-22fd-4e61-8099-a7fa1a0bb681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a522f45f52a4868875f5e2f6824b0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 1/200 | Training loss 3.8084 |  Val accuracy 0.3524 | Test accuracy 0.3507\n",
      "Epoch 3/200 | Training loss 3.9402 |  Val accuracy 0.4905 | Test accuracy 0.4695\n",
      "Epoch 4/200 | Training loss 3.2394 |  Val accuracy 0.5095 | Test accuracy 0.4873\n",
      "Epoch 5/200 | Training loss 2.7456 |  Val accuracy 0.5952 | Test accuracy 0.5653\n",
      "Epoch 6/200 | Training loss 1.9726 |  Val accuracy 0.6810 | Test accuracy 0.6459\n",
      "Epoch 7/200 | Training loss 1.3326 |  Val accuracy 0.7952 | Test accuracy 0.7222\n"
     ]
    }
   ],
   "source": [
    "train_cora(features, adj, gcn_layer, 32, 200, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb437c31-9577-484c-8dd3-d3f026882669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#degree matrix of adjacency matrix adj\n",
    "deg = tf.reduce_sum(adj, axis = -1)\n",
    "# print(\"adjacency matrix\",adj,\"\\n\")\n",
    "# print(\"degree matrix\",deg,\"\\n\")\n",
    "# print(adj/deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7e73753-1fc2-462d-8612-3e938cd95d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e8a10497946426f98ac1f0c1e18d253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 1/200 | Training loss 1.9495 |  Val accuracy 0.3429 | Test accuracy 0.3308\n",
      "Epoch 2/200 | Training loss 1.7526 |  Val accuracy 0.3667 | Test accuracy 0.3520\n",
      "Epoch 3/200 | Training loss 1.5504 |  Val accuracy 0.4000 | Test accuracy 0.3919\n",
      "Epoch 4/200 | Training loss 1.3480 |  Val accuracy 0.4571 | Test accuracy 0.4741\n",
      "Epoch 5/200 | Training loss 1.1526 |  Val accuracy 0.5619 | Test accuracy 0.5615\n",
      "Epoch 6/200 | Training loss 0.9717 |  Val accuracy 0.6571 | Test accuracy 0.6383\n",
      "Epoch 7/200 | Training loss 0.8127 |  Val accuracy 0.6810 | Test accuracy 0.6845\n",
      "Epoch 8/200 | Training loss 0.6741 |  Val accuracy 0.7143 | Test accuracy 0.7125\n",
      "Epoch 9/200 | Training loss 0.5522 |  Val accuracy 0.7714 | Test accuracy 0.7328\n",
      "Epoch 10/200 | Training loss 0.4466 |  Val accuracy 0.8000 | Test accuracy 0.7506\n",
      "Epoch 11/200 | Training loss 0.3581 |  Val accuracy 0.8095 | Test accuracy 0.7621\n",
      "Epoch 12/200 | Training loss 0.2850 |  Val accuracy 0.8143 | Test accuracy 0.7714\n",
      "Epoch 17/200 | Training loss 0.0872 |  Val accuracy 0.8190 | Test accuracy 0.7727\n"
     ]
    }
   ],
   "source": [
    "# train gcn using mean pooling \n",
    "train_cora(features, adj/deg,gcn_layer, 32, 200, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5b729c5-d849-4b89-abec-5fa66b7f8649",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_deg = tf.linalg.diag(1.0/tf.sqrt(deg))\n",
    "norm_adj= tf.matmul(norm_deg,tf.matmul(adj,norm_deg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4022fce-022c-43aa-b88f-2b7262e49cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "687a828599f74eb49f573e30157a42b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Epoch 1/200 | Training loss 1.9416 |  Val accuracy 0.4143 | Test accuracy 0.4402\n",
      "Epoch 2/200 | Training loss 1.7342 |  Val accuracy 0.4476 | Test accuracy 0.4754\n",
      "Epoch 3/200 | Training loss 1.5157 |  Val accuracy 0.5143 | Test accuracy 0.5352\n",
      "Epoch 4/200 | Training loss 1.2833 |  Val accuracy 0.5714 | Test accuracy 0.5895\n",
      "Epoch 5/200 | Training loss 1.0641 |  Val accuracy 0.6190 | Test accuracy 0.6429\n",
      "Epoch 6/200 | Training loss 0.8676 |  Val accuracy 0.6857 | Test accuracy 0.6764\n",
      "Epoch 7/200 | Training loss 0.6967 |  Val accuracy 0.7095 | Test accuracy 0.7044\n",
      "Epoch 9/200 | Training loss 0.4342 |  Val accuracy 0.7238 | Test accuracy 0.7375\n",
      "Epoch 10/200 | Training loss 0.3397 |  Val accuracy 0.7476 | Test accuracy 0.7464\n",
      "Epoch 11/200 | Training loss 0.2649 |  Val accuracy 0.7524 | Test accuracy 0.7557\n",
      "Epoch 12/200 | Training loss 0.2058 |  Val accuracy 0.7714 | Test accuracy 0.7629\n",
      "Epoch 13/200 | Training loss 0.1592 |  Val accuracy 0.7810 | Test accuracy 0.7680\n",
      "Epoch 15/200 | Training loss 0.0946 |  Val accuracy 0.7810 | Test accuracy 0.7680\n"
     ]
    }
   ],
   "source": [
    "train_cora(features, norm_adj, gcn_layer, 32, 200, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f347bb0-d040-4c09-b929-df053d230cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a moment let's make the adj marix orginal matrix\n",
    "adj_org = cora_g.a.todense()\n",
    "adj_org = adj_org.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae62cac6-0dc5-457b-b409-30d67b743afe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm,trange\n",
    "from time import sleep \n",
    "def train_cora_diff(fts,adj,gnn_lyr,units, epochs ,lr ):\n",
    "    \n",
    "    best_accuracy=0.0\n",
    "    \n",
    "    layer1 = tf.keras.layers.Dense(units) # transform function for first GNN layer\n",
    "    layer2 = tf.keras.layers.Dense(7) # transform function for second GNN layer \n",
    "    \n",
    "    def cora_gnn(fts,adj):   # entire GNN architecutre\n",
    "        l = tf.Variable(initial_value=1, trainable = True , dtype = tf.float32)\n",
    "        adj = adj + l*np.eye(adj.shape[0])\n",
    "        hidden = gnn_lyr(fts,adj,layer1,tf.nn.relu) # first layer of the GNN architecture \n",
    "        logits = gnn_lyr(hidden,adj,layer2, tf.identity) \n",
    "        return logits \n",
    "    #custom training loop\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "     \n",
    "    def getMetrics(predicts):\n",
    "        \n",
    "        nonlocal best_accuracy\n",
    "        val_accuracy = masked_accuracy(predicts, labels, val_mask)\n",
    "        test_accuracy = masked_accuracy(predicts, labels, test_mask)\n",
    "        \n",
    "        if val_accuracy>best_accuracy:\n",
    "            best_accuracy=val_accuracy\n",
    "            tqdm.write(\"\\rEpoch {}/{} | Training loss {:.4f} |  Val accuracy {:.4f} | Test accuracy {:.4f}\".\n",
    "                  format(epoch,epochs,loss.numpy(),val_accuracy.numpy(),test_accuracy.numpy()),\n",
    "                 end=\"\\n\" if epoch<epochs+1 else \"\" )\n",
    "\n",
    "    for epoch in trange(1,epochs+1):\n",
    "        with tf.GradientTape() as tape:\n",
    "           \n",
    "            logits = cora_gnn(fts,adj)  #calculated logits \n",
    "            loss = masked_softmax_cross_entropy(logits, labels, train_mask)\n",
    "            \n",
    "        variables = tape.watched_variables()\n",
    "        if epoch==1 :\n",
    "            print(\"num of watching variables: \", len(variables))\n",
    "        gradients = tape.gradient(loss, variables)\n",
    "        optimizer.apply_gradients(zip(gradients, variables))\n",
    "        \n",
    "        # I'm gonna calculate predicts again \n",
    "        predicts= cora_gnn(fts,adj)\n",
    "        #predicts = logits\n",
    "        sleep(0.001)\n",
    "        getMetrics(predicts)\n",
    "        \n",
    "        if epoch==epochs:\n",
    "            print(\"trade-off constant: \", variables[-1].numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12e9d362-06aa-4e7a-8f22-8eb753c70389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b88f6a3d9a433a9a953d2a073b6d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of watching variables:  5\n",
      "Epoch 1/200 | Training loss 3.9408 |  Val accuracy 0.2952 | Test accuracy 0.3240\n",
      "Epoch 2/200 | Training loss 6.3967 |  Val accuracy 0.3429 | Test accuracy 0.3707\n",
      "Epoch 3/200 | Training loss 2.5959 |  Val accuracy 0.4952 | Test accuracy 0.5106\n",
      "Epoch 4/200 | Training loss 1.5101 |  Val accuracy 0.5571 | Test accuracy 0.5237\n",
      "Epoch 5/200 | Training loss 1.2208 |  Val accuracy 0.6762 | Test accuracy 0.6387\n",
      "Epoch 6/200 | Training loss 0.9422 |  Val accuracy 0.6857 | Test accuracy 0.6832\n",
      "Epoch 8/200 | Training loss 0.6520 |  Val accuracy 0.6952 | Test accuracy 0.7095\n",
      "Epoch 9/200 | Training loss 0.4889 |  Val accuracy 0.7286 | Test accuracy 0.7129\n",
      "Epoch 10/200 | Training loss 0.3200 |  Val accuracy 0.7381 | Test accuracy 0.7218\n",
      "Epoch 11/200 | Training loss 0.2555 |  Val accuracy 0.7619 | Test accuracy 0.7193\n",
      "Epoch 22/200 | Training loss 0.0801 |  Val accuracy 0.7667 | Test accuracy 0.7252\n",
      "Epoch 25/200 | Training loss 0.0588 |  Val accuracy 0.7810 | Test accuracy 0.7290\n",
      "Epoch 38/200 | Training loss 0.0207 |  Val accuracy 0.7810 | Test accuracy 0.7409\n",
      "Epoch 39/200 | Training loss 0.0193 |  Val accuracy 0.7857 | Test accuracy 0.7417\n",
      "Epoch 41/200 | Training loss 0.0169 |  Val accuracy 0.7905 | Test accuracy 0.7434\n",
      "Epoch 49/200 | Training loss 0.0108 |  Val accuracy 0.7952 | Test accuracy 0.7455\n",
      "Epoch 53/200 | Training loss 0.0089 |  Val accuracy 0.8000 | Test accuracy 0.7451\n",
      "Epoch 64/200 | Training loss 0.0057 |  Val accuracy 0.8048 | Test accuracy 0.7430\n",
      "Epoch 65/200 | Training loss 0.0055 |  Val accuracy 0.8095 | Test accuracy 0.7434\n",
      "Epoch 150/200 | Training loss 0.0009 |  Val accuracy 0.8143 | Test accuracy 0.7498\n",
      "trade-off constant:  1.0134532\n"
     ]
    }
   ],
   "source": [
    "train_cora_diff(features, adj_org, gcn_layer, 32, 200, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ec4a41-3206-4e16-8a78-f54fc22eb1b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
